{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестовое задание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(max_df = 0.9, min_df = 10, ngram_range=(1, 3))\n",
    "tfidf_vect = TfidfVectorizer(max_df = 0.9, min_df = 10, ngram_range=(1, 3))\n",
    "porter_stemmer = nltk.stem.PorterStemmer()\n",
    "tok = count_vect.build_tokenizer()\n",
    "clf = LogisticRegression(solver='liblinear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cкачиваем файл с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Electronics_5.json.gz\n",
    "#или\n",
    "#!wget https://drive.google.com/open?id=1DwwTyIn5zW7KTxp4bONHtKNa6DlT9PUj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Если необходимо, преобразуем JSON к CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_json ('reviews_Electronics_5.json', lines=True )\n",
    "#df.to_csv ('Electronics_5.csv', index = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предобработка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv(\"Electronics_5.csv\")[[\"asin\",\"reviewText\", \"overall\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Добавляем бинрную оценку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat[\"bin\"] = dat.overall > 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отрежем кусок даты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_t, dat = dat, dat[0:50001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dat, test_dat, train_ans, test_ans = train_test_split(\n",
    "    dat.reviewText, dat.bin, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Натравим на необработанные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect.fit(dat.reviewText.apply(lambda x: np.str_(x)))\n",
    "tfidf_vect.fit(dat.reviewText.apply(lambda x: np.str_(x)))\n",
    "count_train_mtrx_dft = count_vect.transform(train_dat.apply(lambda x: np.str_(x)))\n",
    "tfidf_train_mtrx_dft = tfidf_vect.transform(train_dat.apply(lambda x: np.str_(x)))\n",
    "count_test_mtrx_dft = count_vect.transform(test_dat.apply(lambda x: np.str_(x)))\n",
    "tfidf_test_mtrx_dft = tfidf_vect.transform(test_dat.apply(lambda x: np.str_(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Приводим к базовой форме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dat_tr = list(map(lambda elem: (\" \").join(map(lambda s: (porter_stemmer.stem(s)), elem)).lower().translate(str.maketrans('', '', string.punctuation)), map(lambda wrds: tok(wrds), train_dat.apply(lambda x: np.str_(x)))))\n",
    "test_dat_tr = list(map(lambda elem: (\" \").join(map(lambda s: (porter_stemmer.stem(s)), elem)).lower().translate(str.maketrans('', '', string.punctuation)), map(lambda wrds: tok(wrds), test_dat.apply(lambda x: np.str_(x)))))\n",
    "dat[\"words\"] = list(map(lambda elem: (\" \").join(map(lambda s: (porter_stemmer.stem(s)), elem)).lower().translate(str.maketrans('', '', string.punctuation)), map(lambda wrds: tok(wrds), dat.reviewText.apply(lambda x: np.str_(x)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Можно воспользоваться анализатором, который предоставляют векторайзеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anlz = count_vect.build_analyzer()\n",
    "# dat.words = list(map(lambda s: (\" \").join(anlz(s)), dat.reviewText))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Натравим на обработанные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect.fit(dat.words)\n",
    "tfidf_vect.fit(dat.words)\n",
    "count_train_mtrx = count_vect.transform(train_dat_tr)\n",
    "tfidf_train_mtrx = tfidf_vect.transform(train_dat_tr)\n",
    "count_test_mtrx = count_vect.transform(test_dat_tr)\n",
    "tfidf_test_mtrx = tfidf_vect.transform(test_dat_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверим, что получилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разобьем вектора на выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_train_mtrx, count_test_mtrx, count_train_ans, count_test_ans = train_test_split(\n",
    "#     dat_count, dat.bin, test_size=0.2)\n",
    "# #dat_count.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_train_mtrx, tfidf_test_mtrx, tfidf_train_ans, tfidf_test_ans = train_test_split(\n",
    "#     dat_tfidf, dat.bin, test_size=0.2)\n",
    "# #dat_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_train_mtrx_dft, count_test_mtrx_dft, count_train_ans_dft, count_test_ans_dft = train_test_split(\n",
    "#     dat_count_deft, dat.bin, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_train_mtrx_dft, tfidf_test_mtrx_dft, tfidf_train_ans_dft, tfidf_test_ans_dft = train_test_split(\n",
    "#     dat_tfidf_deft, dat.bin, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучим модели и посмотрим их точность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработанные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(count_train_mtrx, train_ans)\n",
    "cout_pred = clf.predict(count_test_mtrx)\n",
    "accuracy_score(cout_pred, test_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(tfidf_train_mtrx, train_ans)\n",
    "tfidf_pred = clf.predict(tfidf_test_mtrx)\n",
    "accuracy_score(tfidf_pred, test_ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дефолтные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(count_train_mtrx_dft, train_ans)\n",
    "cout_pred = clf.predict(count_test_mtrx_dft)\n",
    "accuracy_score(cout_pred, test_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(tfidf_train_mtrx_dft, train_ans)\n",
    "tfidf_pred = clf.predict(tfidf_test_mtrx_dft)\n",
    "accuracy_score(tfidf_pred, test_ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработанные с оптимальными параметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': np.arange(0.1, 3, 0.1),\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "search = GridSearchCV(clf, param_grid, cv=5)\n",
    "search.fit(count_train_mtrx, train_ans)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(test_ans, search.best_estimator_.predict(count_test_mtrx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': np.arange(0.1, 3, 0.1),\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "search = GridSearchCV(clf, param_grid, cv=5)\n",
    "search.fit(tfidf_train_mtrx,  train_ans)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(test_ans, search.best_estimator_.predict(tfidf_test_mtrx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Дефолтные с оптимальными параметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': np.arange(0.1, 3, 0.1),\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "search = GridSearchCV(clf, param_grid, cv=5)\n",
    "search.fit(count_train_mtrx_dft, train_ans)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(test_ans, search.best_estimator_.predict(count_test_mtrx_dft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': np.arange(0.1, 3, 0.1),\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "search = GridSearchCV(clf, param_grid, cv=5)\n",
    "search.fit(tfidf_train_mtrx_dft, train_ans)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(test_ans, search.best_estimator_.predict(tfidf_test_mtrx_dft))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверим баланс классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All :\\n1 - \", sum(dat.bin), \"\\n0 - \", len(dat.bin) - sum(dat.bin)) \n",
    "print(\"Train :\\n1 - \", sum(train_ans), \"\\n0 - \", len(train_ans) - sum(train_ans)) \n",
    "print(\"Test :\\n1 - \", sum(test_ans), \"\\n0 - \", len(test_ans) - sum(test_ans)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
